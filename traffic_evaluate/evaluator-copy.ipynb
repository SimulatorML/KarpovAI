{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "# to log\n",
    "import logging\n",
    "\n",
    "from typing import List\n",
    "\n",
    "# parse json file with transcribed videos\n",
    "import json\n",
    "\n",
    "from llama_index import Document, VectorStoreIndex\n",
    "from llama_index.llms import OpenAI\n",
    "from llama_index.evaluation import DatasetGenerator, RelevancyEvaluator, FaithfulnessEvaluator\n",
    "\n",
    "from llama_index import StorageContext, load_index_from_storage\n",
    "from llama_index import ServiceContext\n",
    "\n",
    "import pandas as pd\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "from llama_index.node_parser import SimpleNodeParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the async code working in the notebook cells\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the API key to the variable\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the logging\n",
    "logging.basicConfig(filename='question_generation.log',  # Name of the log file\n",
    "                    level=logging.DEBUG,     # Logging level\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',  # Format of log messages\n",
    "                    filemode='w')  # Overwrite the log file on each script run\n",
    "\n",
    "logging.debug('Run started')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some of the videos would have more than one node, and the last node may be too short to be used for the questions. We need to discard such nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nodes(nodes):\n",
    "    \"\"\"\n",
    "    Processes a list of nodes based on the following criteria:\n",
    "    \n",
    "    1. If a node has the same title as the previous one, it's added to the result list \n",
    "       only if its word count is more than 50% of the previous node's word count.\n",
    "    2. If a node has a different title, it's simply added to the result list.\n",
    "\n",
    "    Parameters:\n",
    "    - nodes (list): A list of BaseNode objects.\n",
    "\n",
    "    Returns:\n",
    "    - list: A processed list of BaseNode objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty list to store the processed nodes\n",
    "    result = []\n",
    "\n",
    "    # Initialize variables to keep track of the previous node's title and word count\n",
    "    prev_title = None\n",
    "    prev_word_count = 0\n",
    "\n",
    "    # Iterate through the list of nodes\n",
    "    for node in nodes:\n",
    "        current_title = node.metadata['title']\n",
    "        current_word_count = len(node.text.split())\n",
    "\n",
    "        # Check if the current node has the same title as the previous one\n",
    "        if current_title == prev_title:\n",
    "            if current_word_count > 0.5 * prev_word_count:\n",
    "                result.append(node)\n",
    "        else:\n",
    "            result.append(node)\n",
    "\n",
    "        # Update the previous title and word count for the next iteration\n",
    "        prev_title = current_title\n",
    "        prev_word_count = current_word_count\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open json with transcribed videos and parse\n",
    "with open(f\"../data/video_info.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data = data[:4]\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        text=\"\".join(d[\"text\"]),\n",
    "        metadata={\"url\": d[\"url\"][0], \"title\": d[\"title\"][0]},\n",
    "    )\n",
    "    for d in data\n",
    "]\n",
    "\n",
    "# set chunk_size and parse the docs into the nodes\n",
    "chunk_size = 1024 * 8\n",
    "parser = SimpleNodeParser.from_defaults(chunk_size=1024*8)\n",
    "\n",
    "nodes = parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "gpt3 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "service_context_gpt3 = ServiceContext.from_defaults(llm=gpt3, node_parser=parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 1 - сносно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Какие задачи можно решить с помощью ML-симулятора?',\n",
       " 'Какие данные хранятся в базе данных PostgreSQL?']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_gen_query = \"Ты - начинающий спецалист в анализе данных. \\\n",
    "                        На основе приведенного текста составь только один вопрос, \\\n",
    "                        на который можно ответить с помощью текста. \\\n",
    "                        Вопрос должен покрыть как можно больше аспектов в тексте. \\\n",
    "                        Он должен быть только на основе привденного текста \\\n",
    "                        и относиться к области анализа данных\" \n",
    "\n",
    "data_generator_nodes = DatasetGenerator(\n",
    "    nodes=nodes[:2],\n",
    "    service_context=service_context_gpt3,\n",
    "    question_gen_query=question_gen_query\n",
    "    )\n",
    "\n",
    "eval_questions_nodes = data_generator_nodes.generate_questions_from_nodes()\n",
    "\n",
    "eval_questions_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 2 - лучший"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Какие задачи решает ML-симулятор и как он помогает инженеру по машинному обучению?',\n",
       " 'Какие важные нюансы нужно учитывать при хранении данных в Redash и как это может повлиять на аналитический анализ данных?']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_gen_query = \"На основе приведенного текста составь только один вопрос, \\\n",
    "                        на который можно ответить с помощью текста. \\\n",
    "                        Вопрос должен покрыть как можно больше аспектов в тексте. \\\n",
    "                        Он должен быть только на основе привденного текста \\\n",
    "                        и относиться к области анализа данных\" \n",
    "\n",
    "data_generator_nodes = DatasetGenerator(\n",
    "    nodes=nodes[:2],\n",
    "    service_context=service_context_gpt3,\n",
    "    question_gen_query=question_gen_query\n",
    "    )\n",
    "\n",
    "eval_questions_nodes = data_generator_nodes.generate_questions_from_nodes()\n",
    "\n",
    "eval_questions_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 3 - дает больше одного"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Какие задачи решает ML-симулятор?',\n",
       " 'Какие данные хранятся в специальной базе данных в PostgreSQL?',\n",
       " 'Как Redash отображает результаты запросов?',\n",
       " 'Как Redash отображает время в своем формате?',\n",
       " 'Какие форматы отображения даты доступны в Redash?',\n",
       " 'Какие нюансы связаны с отображением времени в Redash?',\n",
       " 'Какие проблемы могут возникнуть при отборе записей по времени в Redash?',\n",
       " 'Как данные хранятся в базе данных PostgreSQL?',\n",
       " 'Какой формат времени используется в базе данных PostgreSQL?',\n",
       " 'Какие форматы времени поддерживает Redash?',\n",
       " 'Какие различия между форматом хранения данных и их отображением в Redash?']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_gen_query = \"Я хочу создать список эталонных вопросов к корпусу текстов. \\\n",
    "                      Эталонный вопрос относится к области анализа данных\\\n",
    "                      и на него можно ответить с помощью соответствующего текста.\\\n",
    "                      Вопрос должен покрыть как можно больше аспектов в тексте.\\\n",
    "                      Составь один эталонный вопрос к этому тексту.\"\n",
    "\n",
    "\n",
    "data_generator_nodes = DatasetGenerator(\n",
    "    nodes=nodes[:2],\n",
    "    service_context=service_context_gpt3,\n",
    "    question_gen_query=question_gen_query\n",
    "    )\n",
    "\n",
    "eval_questions_nodes = data_generator_nodes.generate_questions_from_nodes()\n",
    "\n",
    "eval_questions_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 4 - сносно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Какие задачи можно решить с помощью ML-симулятора?',\n",
       " 'Какие данные хранятся в базе данных PostgreSQL?']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_gen_query = \"На русском языке. только один вопрос на текст! Это должен быть именно один вопрос\"\n",
    "\n",
    "data_generator_nodes = DatasetGenerator(\n",
    "    nodes=nodes[:2],\n",
    "    service_context=service_context_gpt3,\n",
    "    question_gen_query=question_gen_query\n",
    "    )\n",
    "\n",
    "eval_questions_nodes = data_generator_nodes.generate_questions_from_nodes()\n",
    "\n",
    "eval_questions_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 5 - твой вариант - больше двух вопросов на ноду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Что такое Симулятор ML и для чего он нужен?',\n",
       " 'Какие задачи можно решить с помощью Симулятора ML?',\n",
       " 'Какой опыт можно получить, проходя Симулятор ML?',\n",
       " 'Как Симулятор ML поможет при приеме на работу?',\n",
       " 'Как Симулятор ML поможет при выполнении новых задач на работе?',\n",
       " 'Что такое Redash и как он отображает данные?',\n",
       " 'Где хранятся данные в Redash?',\n",
       " 'Как Redash отображает время?',\n",
       " 'Какой формат отображения даты использует Redash?',\n",
       " 'Какие нюансы есть в отображении данных в Redash?',\n",
       " 'Какие настройки есть в Redash для отображения даты?',\n",
       " 'Какие форматы даты можно использовать в Redash?',\n",
       " 'Какие данные хранятся в базе данных в формате PostgreSQL?',\n",
       " 'Какие проблемы могут возникнуть при отборе записей по времени в Redash?',\n",
       " 'Какие инструменты существуют для визуализации данных, похожие на Redash?']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator_nodes = DatasetGenerator(\n",
    "    nodes=nodes[:2],\n",
    "    service_context=service_context_gpt3,\n",
    "    num_questions_per_chunk=2,\n",
    "    question_gen_query=\"На русском языке\"\n",
    "    )\n",
    "\n",
    "eval_questions_nodes = data_generator_nodes.generate_questions_from_nodes()\n",
    "\n",
    "eval_questions_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 6 - пример того, как на некоторые ноды бот не приводит вопрос (см вторую ноду)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Какие задачи можно решить с помощью ML-симулятора?',\n",
       " 'Если бы мы просто перевели формат колонки Creation Time в текстовый формат, мы могли бы увидеть, как она выглядит. Однако, в Redash текстовый формат уже не форматирует данные, поэтому мы не можем узнать, как они хранятся в базе данных PostgreSQL.',\n",
       " 'Как можно интерпретировать график и сделать статистический вывод?',\n",
       " 'Какие задачи решает аналитик данных в банках?',\n",
       " 'Какие факторы могут влиять на то, что товарный запас не был распродан в некоторых магазинах?',\n",
       " 'Какие детали и нюансы вы заметили при рассмотрении задач других аналитиков?',\n",
       " 'Какие проблемы с организацией работы и атмосферой были упомянуты девочкой, которая работала в магните?',\n",
       " 'Какие проблемы возникли при выполнении проектов и как вы планируете к ним подходить в будущем?']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator_nodes_proc = DatasetGenerator(\n",
    "    nodes=processed_nodes,\n",
    "    service_context=service_context_gpt3,\n",
    "    # num_questions_per_chunk=1,\n",
    "    question_gen_query=question_gen_query\n",
    "    )\n",
    "\n",
    "eval_questions_nodes_proc = data_generator_nodes_proc.generate_questions_from_nodes()\n",
    "\n",
    "eval_questions_nodes_proc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karpovai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
