{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load API key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "# to log\n",
    "import logging\n",
    "\n",
    "from typing import List\n",
    "\n",
    "# parse json file with transcribed videos\n",
    "import json\n",
    "\n",
    "from llama_index import (Document, \n",
    "                         VectorStoreIndex,\n",
    "                         StorageContext,\n",
    "                         load_index_from_storage,\n",
    "                         ServiceContext\n",
    ")\n",
    "from llama_index.evaluation import (DatasetGenerator, \n",
    "                                    RelevancyEvaluator, \n",
    "                                    FaithfulnessEvaluator,\n",
    "                                    generate_question_context_pairs,\n",
    "                                    EmbeddingQAFinetuneDataset\n",
    ")\n",
    "\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the async code working in the notebook cells\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the API key to the variable\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the logging\n",
    "logging.basicConfig(filename='question_generation.log',  # Name of the log file\n",
    "                    level=logging.DEBUG,     # Logging level\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s',  # Format of log messages\n",
    "                    filemode='w')  # Overwrite the log file on each script run\n",
    "\n",
    "logging.debug('Run started')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some of the videos would have more than one node, and the last node may be too short to be used for the questions. We need to discard such nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_nodes(nodes):\n",
    "    \"\"\"\n",
    "    Processes a list of nodes based on the following criteria:\n",
    "    \n",
    "    1. If a node has the same title as the previous one, it's added to the result list \n",
    "       only if its word count is more than 50% of the previous node's word count.\n",
    "    2. If a node has a different title, it's simply added to the result list.\n",
    "\n",
    "    Parameters:\n",
    "    - nodes (list): A list of BaseNode objects.\n",
    "\n",
    "    Returns:\n",
    "    - list: A processed list of BaseNode objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty list to store the processed nodes\n",
    "    result = []\n",
    "\n",
    "    # Initialize variables to keep track of the previous node's title and word count\n",
    "    prev_title = None\n",
    "    prev_word_count = 0\n",
    "\n",
    "    # Iterate through the list of nodes\n",
    "    for node in nodes:\n",
    "        current_title = node.metadata['title']\n",
    "        current_word_count = len(node.text.split())\n",
    "\n",
    "        # Check if the current node has the same title as the previous one\n",
    "        if current_title == prev_title:\n",
    "            if current_word_count > 0.5 * prev_word_count:\n",
    "                result.append(node)\n",
    "        else:\n",
    "            result.append(node)\n",
    "\n",
    "        # Update the previous title and word count for the next iteration\n",
    "        prev_title = current_title\n",
    "        prev_word_count = current_word_count\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open json with transcribed videos and parse\n",
    "with open(f\"../data/video_info.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "data = data[:3]\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        text=\"\".join(d[\"text\"]),\n",
    "        metadata={\"url\": d[\"url\"][0], \"title\": d[\"title\"][0]},\n",
    "    )\n",
    "    for d in data\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the truncated video json to a file\n",
    "\n",
    "with open('video_info_test.json', 'w', encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set chunk_size and parse the docs into the nodes\n",
    "chunk_size = 1024 * 3\n",
    "parser = SimpleNodeParser.from_defaults(chunk_size=chunk_size)\n",
    "\n",
    "nodes = parser.get_nodes_from_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "gpt3 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "service_context_gpt3 = ServiceContext.from_defaults(llm=gpt3, node_parser=parser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now try with `generate_question_context_pairs` function to have node - question link preserved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:10<00:00,  2.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# make a prompt template\n",
    "qa_generate_prompt_tmpl = \"\"\"\\\n",
    "Внизу указана контекстная информация.\n",
    "\n",
    "---------------------\n",
    "{context_str}\n",
    "---------------------\n",
    "\n",
    "На основе приведенного текста составь только один вопрос, \\\n",
    "на который можно ответить с помощью текста. \\\n",
    "Вопрос должен покрыть как можно больше аспектов в тексте. \\\n",
    "Он должен быть только на основе привденного текста \\\n",
    "и относиться к области анализа данных.\"\n",
    "\"\"\"\n",
    "\n",
    "# query based on the nodes list\n",
    "qa_dataset = generate_question_context_pairs(\n",
    "    nodes=nodes, \n",
    "    llm=gpt3, \n",
    "    qa_generate_prompt_tmpl=qa_generate_prompt_tmpl,\n",
    "    num_questions_per_chunk=1 # this wil anyway not appear in the query, can be any value :)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Какие задачи решает ML-симулятор и как он помогает инженерам по машинному обучению при приеме на работу и в работе?\n",
      "Как Redash отображает дату и время в своих результатных данных и как они хранятся в базе данных PostgreSQL?\n",
      "Как Redash отображает данные и как это может повлиять на результаты анализа данных?\n",
      "Какие нюансы и проблемы могут возникнуть при работе с данными в Redash, связанные с форматированием чисел и дат?\n",
      "Как можно использовать обратный эксперимент и сравнение графиков для анализа влияния ковида на показы рекламы мобильных игр?\n"
     ]
    }
   ],
   "source": [
    "# show the questions generated\n",
    "\n",
    "for q in qa_dataset.queries.values():\n",
    "    print(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries : {'80ffe444-7500-42a3-9bb3-5580dd745125': 'Какие задачи решает ML-симулятор и как он помогает инженерам по машинному обучению при приеме на работу и в работе?', '1102533d-17ad-43ce-8b1b-04fa8b76c1e8': 'Как Redash отображает дату и время в своих результатных данных и как они хранятся в базе данных PostgreSQL?', 'a60f0d8d-4dd3-4dc2-a233-2b5c9223fe1a': 'Как Redash отображает данные и как это может повлиять на результаты анализа данных?', '97d90959-ee63-456e-8d55-1067d8180a2a': 'Какие нюансы и проблемы могут возникнуть при работе с данными в Redash, связанные с форматированием чисел и дат?', 'c822a435-6d44-4dca-bd5d-5c05014ec15d': 'Как можно использовать обратный эксперимент и сравнение графиков для анализа влияния ковида на показы рекламы мобильных игр?'}\n",
      "corpus : {'5c86129f-2559-4640-b908-c25b3da2ee60': 'Без опыта работы человека часто не берут на работу. А без работы ему часто не получается получить опыта на работе. Классический парадокс, бесконечная петля. Если вы думаете, что она возникает везде, но не в машинном обучении, то это не так. В подробнейшем большинстве обучающих курсов вам покажут, как обучать модели, как применять алгоритм. Вообще это не дает комплексного понимания того, чем же занимается инженер по машинному обучению. По факту есть куча чего до. От банального взять таску в тасктрекере, откуда-то данные выгрузить, куда-то их загрузить, какой-то стриминг настроить, потом обучить модель, применить ее к чему-то, а потом ее надо задеплоить или ее результат визуализировать, построить мониторинг, возможно провести АБТС. В общем, это куча всего. Это целый пайплайн, в котором еще можно много-много чего накидать. ML-симулятор призван как раз эту задачу решить. То есть это инфраструктура с задачами разного уровня. Вы туда приходите, понимаете, что вы сейчас уже можете сделать, а что вы делать не можете, пытаетесь это сделать, на этом учитесь и приобретаете этот комплексный охват. По окончанию симулятора вы можете уверенно сказать, я знаю, как решать эти задачи. Это вам поможет либо при приеме на работу, либо когда на работе у вас будет новая задача, будете знать, что с ней делать. Меня зовут Валерий Бабушкин, я хед в DataScience Blockchain.com и я приглашаю вас в симулятор инженера по машинному обучению.', '7002e54c-7bd2-4b2e-8883-9a16a1421d58': 'Перед тем, как мы двинемся дальше, хотел бы еще пару слов сказать про Redash и про то, как он отображает данные. Важно понимать, что сами наши данные, как я уже говорил, хранятся в специальной базе данных в PostgreSQL, а Redash — это некоторый инструмент, который позволяет как писать запросы в базу данных, так и получать и смотреть на результат. И вот здесь скроется некоторый нюанс, потому что то, как Redash отображает результат, далеко не всегда совпадает с тем, как данные хранятся на самом деле и в каком-то смысле, как они на самом деле выглядят. Сейчас поясню, что я имею в виду. Давайте начнем с такого момента, как Redash отображает время. Если мы просто выгрузим несколько строчек из таблички orders, мы увидим, что у нас есть колоночка с временем создания заказа, и здесь мы видим, что формат довольно такой необычный. Соответственно, число, месяц и год разделены вот таким вот слэшем, а год записан только двумя последними цифрами. И вот это уже на самом деле то, как Redash отображает дату. Где-то в Redash есть настройка, что если он видит дату, то он сразу же переводит ее в такой формат. Наверное, вы видели, что, например, в том же самом Excel дату можно отображать довольно большим количеством в разных форматах. Сначала день, потом год, сначала год, потом день и так далее. То же самое в Redash. По умолчанию стоит вот такой формат отображения даты. При этом на самом деле дата хранится в более таком стандартном для анализа данных формате, где полностью сначала указывается год, месяц, день, и потом через пробелы двоеточия указывается, соответственно, минута, прошу прощения, часы, минуты и секунды. И вот обратите внимание, что это как раз-таки время второй, второго Order ID у нас, и Redash, допустим, секунды не отображает. Вот это вовсе не означает, что этих секунд нет на самом деле, это просто означает, что немножко вот так вот сокращает формат Redash. И забегая чуть вперед, если бы мы хотели отобрать, соответственно, запись, где у нас время, Creation Time вот такое, то вот такая вот форма записи у нас бы не сработала. Видите, мы бы вообще не вернули, прошу прощения, здесь я, да, ну, кстати, вот, была бы ошибка, что вообще как бы мы не смогли бы здесь так сравнить, и вот видите, здесь даже Redash нам сам бы написал, что скорее всего у нас в другом формате на самом деле хранится наше время. А если бы мы использовали для отбора нужных нам наблюдений время вот в таком формате, то все бы сработало. Мы чуть позже научимся уже отбирать нужные нам записи при помощи Wear, пока это просто демонстрация, которая основана для того, нужна для того, чтобы вы понимали, как на самом деле хранятся данные. И вот данные в самой базе данных в нашем постгрузе хранятся именно в таком формате. И когда вы дальше будете работать, например, с днями, чтобы отобрать только, допустим, 8 августа, 24 числа 2022 года, мы будем использовать запись именно вот такую.', '62351074-e1f7-4182-ae4a-eef577eff402': 'Redash при этом, если мы выведем данные, он отобразит их немножко иначе, и он просто, во-первых, не станет отображать секунды, во-вторых, соответственно, здесь у нас не отобразятся полный год, допустим. Но это именно Redash так отображает данные, и нет ничего странного в этом, потому что это нормально. Существует довольно много инструментов, которые как-то у себя в своем типе визуализации немного как-то там используют свои форматы. И вы на работе можете работать не в Redash, а в каких-нибудь других системах для написания запросов, и, возможно, они тоже будут как-то немножко форматировать результаты под себя. Нужно просто понимать, что зачастую формат, который хранится в самих данных, и формат, который отображается, он может различаться. Второй пример тоже довольно показательный. Давайте, например, представим, что у нас задача посчитать среднее количество заказов на пользователя. У нас было 10, соответственно, заказов и, соответственно, 7 пользователей. Если мы посчитаем вот эту вот, прошу прощения, здесь просто select. Если мы посчитаем вот такую вот запись, то мы получим 1,43. И можно подумать, как будто у нас только два знака после запятой. Но если бы мы, на самом деле, допустим, вот скачали бы наш результат, такой CSV-файлик, и посмотрели бы, что вот там получилось, то мы бы увидели, что после запятой вы видите довольно много знаков в том числе. В этом смысле Redash просто, как только видит числа, у которых есть знаки после запятой, округляет до двух. И если бы в задаче вас просили бы посчитайте, например, вот orders per user, и округлите до двух знаков после запятой, вы бы сделали какой-то такой запросик и посмотрели бы, о, у меня уже до двух знаков округлено, отлично. И отправили бы на проверку, то, возможно, вы могли бы получить ошибку. Надо более явно округлить до двух знаков после запятой, и теперь это уже будет верный ответ. При этом обратите внимание, что с точки зрения Redash вот эти две записи, они никак не отличаются. Что 10 деленное на 7, что round 10 деленное на 7. Но это только потому, что Redash просто сам у себя вот на этом фронтенде своем уже, соответственно, округляет немножко до двух знаков только после запятой. Вот, это просто важно помнить, что в задачках, например, вас часто будут просить округлить какую-нибудь метрику до двух знаков, и если вы увидите, что у вас в Redash как будто уже округлено, не верьте ему, на самом деле сделайте еще раз round, потому что на самом деле вы как бы отправите в нашу систему проверки не округленный до двух знаков, не соответственно не 1, там, да, 43, а вот 1, 42, 8, 5, 7 и так далее. И может не пройтись просто проверка на правильность. Вот, это два таких важных нюанса. Соответственно, важно понимать, что Redash может хранить данные немного иначе, чем это выглядит. И тоже, забегая уже вперед, мы на самом деле потом с вами научимся смотреть на то, как данные выглядят на самом деле.', '84d01643-d9c8-44f1-9249-8e10c5a9a243': 'Вот здесь, вот в этом примере, например, Orders, тоже всегда можно было бы посмотреть, как у нас выглядит колоночка Creation Time, если бы мы просто перевели ее формат текстовый. Текстовый формат Redash уже никак не, соответственно, форматирует, и вот мы могли бы убедиться, что на самом деле вот в таком формате хранится у нас с вами эта запись. И в справедливости ради, если бы мы 10, деленное на 7, тоже перевели бы в текстовый формат, мы бы увидели, что там сильно больше знаков после запятой, прошу прощения, сильно больше знаков после запятой, потому что, опять же, это просто уже Redash округлил нам это число, а на самом деле там сильно больше знаков. Вот, это два таких нюанса, и при этом, как я уже сказал, что ладно бы, если это было исключительно там просто только для курса важно, но в каком-то смысле и на реальной работе вы сможете столкнуться с тем, что если вы подумаете, допустим, что здесь у вас там уже округление произведено, а для каких-то дальнейших вычислений, вот для какой-то работы там целого пайплайна аналитического все-таки довольно важно, чтобы, например, аналитик выдавал какие-то значения, округленные до двух знаков, то вы должны в своем коде явно прописывать округление уже, соответственно, при помощи функции, а не доверяя тому, что просто Redash сам округляет для более удобного восприятия. Вот такая вот важная история, надеюсь, она пригодится вам при решении наших задачек и в работе может реально пригодиться и сэкономит вам, возможно, время для поиска ошибки, когда вы думаете, что там у вас уже округлено до двух знаков, а на самом деле просто, соответственно, этот Redash так сделал. Или когда в примере ожидаемого результата написана дата в формате 2022.1409, а Redash возвращает через эти слэши, и вы думаете, как бы мне там срочно переформатировать формат даты. Ничего страшного, просто помните, что на самом деле это Redash немного так подкручивает у себя чисто визуально данные, и просто можете теперь более аккуратно решать наши задачки.', '549c9516-c8d9-432e-a3df-cc1fb928d7c4': 'Моя любимая рубрика — это АБ-эксперименты без АБ-экспериментов. Сейчас поясню, что я имею в виду. На практике иногда происходят события, которые никак не предугадать. Вот случился ковид. И сразу все стали бросаться смотреть на графики, как ковид на что-нибудь повлиял. Вот, например, классический такой график. Как ковид повлиял, например, на показы рекламы мобильных игр в ленте. И вот мы видим, что что-то подросло. Понятное дело, что тяжело провести АБ-тест с вопросом, как ковид влияет на показы АБ-тестов. Как минимум, звучит не очень этично. Как ковид влияет на показы рекламы. И на самом деле на практике, на моей практике, это тоже очень частый вопрос. Прибегают какие-то продукты, менеджеры, другие отделы. Говорят, Толя, уже вчера выкатили. АБ-тест нужно было провести позавчера, поэтому сорян. Вот смотри, вот мы выкатили, и вот что-то поросло-падало. Что делать в таких ситуациях? Знаешь, такая классическая методология научная говорит, что ничего. Это псевдоэксперимент, все, никаких выводов сделать нельзя. На практике не очень полезный ответ. То есть ковид действительно либо повлиял, либо не повлиял. Как можно этот график интерпретировать и попробовать сделать какой-то статвывод все-таки? Если откатиться немножко, если уже выкатили, то можно закатить обратно. Взять маленькую группу пользователей. Это, кстати, интересный поинт. И провести не прямой эксперимент, когда мы на большом количестве контроль и на маленькой мы тестируем гипотезу, а провести обратный эксперимент, когда мы на всех уже раскатили, еще вчера, а на какую-то маленькую тестовую группу обратно закатили. Это, кстати, классно, потому что обычно все представляют, что АБ-тест – это что-то, когда мы наоборот тестируем, а тут мы наоборот отменяем и смотрим результат. Мы же тестируем, чтобы пользователей не обидеть, и тестируем какой-то маленькой группе. А если уже раскатили, можно провести обратный и сделать все правильно. Ну, а если все-таки глобальная ситуация? Ну, тогда рисуем два графика недели к неделю, берем линейку и смотрим, на сколько миллиметров, сантиметров вырос график. То есть здесь, в принципе, можно, получается, тоже статистически сравнивать просто, грубо говоря, эту же метрику с самой собой? Не статистически, а с линеечкой, скорее. Потому что неделя к неделе все будет краситься, и эффект сезонности всегда будет давать созначимые изменения, созначимые результаты. Тут так, на глаз, на 2%, на 3%. А какая у нас сезонность обычно, а какая сезонность сегодня. И если там вырос на 20%, то, скорее всего, что-то произошло. Понятно. Ну вот, кстати, с раскатом обратно прикольно. Я правильно понимаю, что это отчасти напоминает ухудшающий АБ-тест?'}\n",
      "relevant_docs : {'80ffe444-7500-42a3-9bb3-5580dd745125': ['5c86129f-2559-4640-b908-c25b3da2ee60'], '1102533d-17ad-43ce-8b1b-04fa8b76c1e8': ['7002e54c-7bd2-4b2e-8883-9a16a1421d58'], 'a60f0d8d-4dd3-4dc2-a233-2b5c9223fe1a': ['62351074-e1f7-4182-ae4a-eef577eff402'], '97d90959-ee63-456e-8d55-1067d8180a2a': ['84d01643-d9c8-44f1-9249-8e10c5a9a243'], 'c822a435-6d44-4dca-bd5d-5c05014ec15d': ['549c9516-c8d9-432e-a3df-cc1fb928d7c4']}\n"
     ]
    }
   ],
   "source": [
    "# show the question - node pairs\n",
    "\n",
    "for key, value in qa_dataset.dict().items():\n",
    "    print(key, ':', value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the json of the pairs - have a look at it yourself!\n",
    "with open('qa_dataset.json', 'w', encoding=\"utf-8\") as f:\n",
    "    json.dump(qa_dataset.dict(), f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so here we have a connection of node id - question id.  \n",
    "\n",
    "Let's do the following operations:\n",
    "1. get a connection node_id - video_url using nodes list\n",
    "\n",
    "2. get a connection question_id - node_id using our generated q-a dataset\n",
    "3. get a connection question_id - video_url using 2 previous connections\n",
    "4. invert the dict 3 to have video_url: [question_ids list] pairs\n",
    "5. iterate over dict 4, replace question_id by the corresponding question_text\n",
    "6. iterate over original video json and for each dict, append question dict with corresponding url key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': ['https://www.youtube.com/watch?v=Api2RW4ogR4'], 'title': ['Зачем нужно проходить Симулятор ML? | karpov.courses'], 'description': ['Симулятор ML: https://bit.ly/3E4jQos\\n\\nНа старте карьеры многие из нас попадали в замкнутый круг «чтобы получить работу – нужно показать опыт; чтобы получить опыт – нужно, чтобы тебя взяли на работу». Как его разорвать? Найти стажировку? Сделать свой пет-проект?.. \\n\\nМы решили помочь вырваться из этого парадокса и создали симулятор инженера по машинному обучению. Здесь вы научитесь решать задачи, с которыми инженеры сталкиваются ежедневно. Уже в первые месяцы тренировок вы подружитесь со всеми необходимыми для работы инструментами, начнёте понимать полный цикл построения ML-систем и узнаете, как с помощью машинного обучения приносить бизнесу прибыль, что повысит вашу ценность для компании.'], 'audio_path': ['../data/audio/Api2RW4ogR4.mp4'], 'text': ['Без опыта работы человека часто не берут на работу. А без работы ему часто не получается получить опыта на работе. Классический парадокс, бесконечная петля. Если вы думаете, что она возникает везде, но не в машинном обучении, то это не так. В подробнейшем большинстве обучающих курсов вам покажут, как обучать модели, как применять алгоритм. Вообще это не дает комплексного понимания того, чем же занимается инженер по машинному обучению. По факту есть куча чего до. От банального взять таску в тасктрекере, откуда-то данные выгрузить, куда-то их загрузить, какой-то стриминг настроить, потом обучить модель, применить ее к чему-то, а потом ее надо задеплоить или ее результат визуализировать, построить мониторинг, возможно провести АБТС. В общем, это куча всего. Это целый пайплайн, в котором еще можно много-много чего накидать. ML-симулятор призван как раз эту задачу решить. То есть это инфраструктура с задачами разного уровня. Вы туда приходите, понимаете, что вы сейчас уже можете сделать, а что вы делать не можете, пытаетесь это сделать, на этом учитесь и приобретаете этот комплексный охват. По окончанию симулятора вы можете уверенно сказать, я знаю, как решать эти задачи. Это вам поможет либо при приеме на работу, либо когда на работе у вас будет новая задача, будете знать, что с ней делать. Меня зовут Валерий Бабушкин, я хед в DataScience Blockchain.com и я приглашаю вас в симулятор инженера по машинному обучению.\\n']}\n",
      "{'url': ['https://www.youtube.com/watch?v=kYcA_RVDNWM'], 'title': ['Redash display | Симулятор SQL | karpov.courses'], 'description': ['Урок: https://lab.karpov.courses/learning/152/module/1762/lesson/18484/53200/269826/\\nСимулятор SQL: https://bit.ly/3XDroX0'], 'audio_path': ['../data/audio/kYcA_RVDNWM.mp4'], 'text': ['Перед тем, как мы двинемся дальше, хотел бы еще пару слов сказать про Redash и про то, как он отображает данные. Важно понимать, что сами наши данные, как я уже говорил, хранятся в специальной базе данных в PostgreSQL, а Redash — это некоторый инструмент, который позволяет как писать запросы в базу данных, так и получать и смотреть на результат. И вот здесь скроется некоторый нюанс, потому что то, как Redash отображает результат, далеко не всегда совпадает с тем, как данные хранятся на самом деле и в каком-то смысле, как они на самом деле выглядят. Сейчас поясню, что я имею в виду. Давайте начнем с такого момента, как Redash отображает время. Если мы просто выгрузим несколько строчек из таблички orders, мы увидим, что у нас есть колоночка с временем создания заказа, и здесь мы видим, что формат довольно такой необычный. Соответственно, число, месяц и год разделены вот таким вот слэшем, а год записан только двумя последними цифрами. И вот это уже на самом деле то, как Redash отображает дату. Где-то в Redash есть настройка, что если он видит дату, то он сразу же переводит ее в такой формат. Наверное, вы видели, что, например, в том же самом Excel дату можно отображать довольно большим количеством в разных форматах. Сначала день, потом год, сначала год, потом день и так далее. То же самое в Redash. По умолчанию стоит вот такой формат отображения даты. При этом на самом деле дата хранится в более таком стандартном для анализа данных формате, где полностью сначала указывается год, месяц, день, и потом через пробелы двоеточия указывается, соответственно, минута, прошу прощения, часы, минуты и секунды. И вот обратите внимание, что это как раз-таки время второй, второго Order ID у нас, и Redash, допустим, секунды не отображает. Вот это вовсе не означает, что этих секунд нет на самом деле, это просто означает, что немножко вот так вот сокращает формат Redash. И забегая чуть вперед, если бы мы хотели отобрать, соответственно, запись, где у нас время, Creation Time вот такое, то вот такая вот форма записи у нас бы не сработала. Видите, мы бы вообще не вернули, прошу прощения, здесь я, да, ну, кстати, вот, была бы ошибка, что вообще как бы мы не смогли бы здесь так сравнить, и вот видите, здесь даже Redash нам сам бы написал, что скорее всего у нас в другом формате на самом деле хранится наше время. А если бы мы использовали для отбора нужных нам наблюдений время вот в таком формате, то все бы сработало. Мы чуть позже научимся уже отбирать нужные нам записи при помощи Wear, пока это просто демонстрация, которая основана для того, нужна для того, чтобы вы понимали, как на самом деле хранятся данные. И вот данные в самой базе данных в нашем постгрузе хранятся именно в таком формате. И когда вы дальше будете работать, например, с днями, чтобы отобрать только, допустим, 8 августа, 24 числа 2022 года, мы будем использовать запись именно вот такую. Redash при этом, если мы выведем данные, он отобразит их немножко иначе, и он просто, во-первых, не станет отображать секунды, во-вторых, соответственно, здесь у нас не отобразятся полный год, допустим. Но это именно Redash так отображает данные, и нет ничего странного в этом, потому что это нормально. Существует довольно много инструментов, которые как-то у себя в своем типе визуализации немного как-то там используют свои форматы. И вы на работе можете работать не в Redash, а в каких-нибудь других системах для написания запросов, и, возможно, они тоже будут как-то немножко форматировать результаты под себя. Нужно просто понимать, что зачастую формат, который хранится в самих данных, и формат, который отображается, он может различаться. Второй пример тоже довольно показательный. Давайте, например, представим, что у нас задача посчитать среднее количество заказов на пользователя. У нас было 10, соответственно, заказов и, соответственно, 7 пользователей. Если мы посчитаем вот эту вот, прошу прощения, здесь просто select. Если мы посчитаем вот такую вот запись, то мы получим 1,43. И можно подумать, как будто у нас только два знака после запятой. Но если бы мы, на самом деле, допустим, вот скачали бы наш результат, такой CSV-файлик, и посмотрели бы, что вот там получилось, то мы бы увидели, что после запятой вы видите довольно много знаков в том числе. В этом смысле Redash просто, как только видит числа, у которых есть знаки после запятой, округляет до двух. И если бы в задаче вас просили бы посчитайте, например, вот orders per user, и округлите до двух знаков после запятой, вы бы сделали какой-то такой запросик и посмотрели бы, о, у меня уже до двух знаков округлено, отлично. И отправили бы на проверку, то, возможно, вы могли бы получить ошибку. Надо более явно округлить до двух знаков после запятой, и теперь это уже будет верный ответ. При этом обратите внимание, что с точки зрения Redash вот эти две записи, они никак не отличаются. Что 10 деленное на 7, что round 10 деленное на 7. Но это только потому, что Redash просто сам у себя вот на этом фронтенде своем уже, соответственно, округляет немножко до двух знаков только после запятой. Вот, это просто важно помнить, что в задачках, например, вас часто будут просить округлить какую-нибудь метрику до двух знаков, и если вы увидите, что у вас в Redash как будто уже округлено, не верьте ему, на самом деле сделайте еще раз round, потому что на самом деле вы как бы отправите в нашу систему проверки не округленный до двух знаков, не соответственно не 1, там, да, 43, а вот 1, 42, 8, 5, 7 и так далее. И может не пройтись просто проверка на правильность. Вот, это два таких важных нюанса. Соответственно, важно понимать, что Redash может хранить данные немного иначе, чем это выглядит. И тоже, забегая уже вперед, мы на самом деле потом с вами научимся смотреть на то, как данные выглядят на самом деле. Вот здесь, вот в этом примере, например, Orders, тоже всегда можно было бы посмотреть, как у нас выглядит колоночка Creation Time, если бы мы просто перевели ее формат текстовый. Текстовый формат Redash уже никак не, соответственно, форматирует, и вот мы могли бы убедиться, что на самом деле вот в таком формате хранится у нас с вами эта запись. И в справедливости ради, если бы мы 10, деленное на 7, тоже перевели бы в текстовый формат, мы бы увидели, что там сильно больше знаков после запятой, прошу прощения, сильно больше знаков после запятой, потому что, опять же, это просто уже Redash округлил нам это число, а на самом деле там сильно больше знаков. Вот, это два таких нюанса, и при этом, как я уже сказал, что ладно бы, если это было исключительно там просто только для курса важно, но в каком-то смысле и на реальной работе вы сможете столкнуться с тем, что если вы подумаете, допустим, что здесь у вас там уже округление произведено, а для каких-то дальнейших вычислений, вот для какой-то работы там целого пайплайна аналитического все-таки довольно важно, чтобы, например, аналитик выдавал какие-то значения, округленные до двух знаков, то вы должны в своем коде явно прописывать округление уже, соответственно, при помощи функции, а не доверяя тому, что просто Redash сам округляет для более удобного восприятия. Вот такая вот важная история, надеюсь, она пригодится вам при решении наших задачек и в работе может реально пригодиться и сэкономит вам, возможно, время для поиска ошибки, когда вы думаете, что там у вас уже округлено до двух знаков, а на самом деле просто, соответственно, этот Redash так сделал. Или когда в примере ожидаемого результата написана дата в формате 2022.1409, а Redash возвращает через эти слэши, и вы думаете, как бы мне там срочно переформатировать формат даты. Ничего страшного, просто помните, что на самом деле это Redash немного так подкручивает у себя чисто визуально данные, и просто можете теперь более аккуратно решать наши задачки.\\n']}\n",
      "{'url': ['https://www.youtube.com/watch?v=NcDcxOqB52k'], 'title': ['Об A/B тестах без A/B тестов | Никита Маршалкин | karpov.courses'], 'description': ['Симулятор A/B-тестов: http://bit.ly/3ZQCp7t \\n\\nСмотрите полное интервью по ссылке: https://youtu.be/gljfGAkgX_o\\n\\nУчитесь Data Science с нами: https://karpov.courses/'], 'audio_path': ['../data/audio/NcDcxOqB52k.mp4'], 'text': ['Моя любимая рубрика — это АБ-эксперименты без АБ-экспериментов. Сейчас поясню, что я имею в виду. На практике иногда происходят события, которые никак не предугадать. Вот случился ковид. И сразу все стали бросаться смотреть на графики, как ковид на что-нибудь повлиял. Вот, например, классический такой график. Как ковид повлиял, например, на показы рекламы мобильных игр в ленте. И вот мы видим, что что-то подросло. Понятное дело, что тяжело провести АБ-тест с вопросом, как ковид влияет на показы АБ-тестов. Как минимум, звучит не очень этично. Как ковид влияет на показы рекламы. И на самом деле на практике, на моей практике, это тоже очень частый вопрос. Прибегают какие-то продукты, менеджеры, другие отделы. Говорят, Толя, уже вчера выкатили. АБ-тест нужно было провести позавчера, поэтому сорян. Вот смотри, вот мы выкатили, и вот что-то поросло-падало. Что делать в таких ситуациях? Знаешь, такая классическая методология научная говорит, что ничего. Это псевдоэксперимент, все, никаких выводов сделать нельзя. На практике не очень полезный ответ. То есть ковид действительно либо повлиял, либо не повлиял. Как можно этот график интерпретировать и попробовать сделать какой-то статвывод все-таки? Если откатиться немножко, если уже выкатили, то можно закатить обратно. Взять маленькую группу пользователей. Это, кстати, интересный поинт. И провести не прямой эксперимент, когда мы на большом количестве контроль и на маленькой мы тестируем гипотезу, а провести обратный эксперимент, когда мы на всех уже раскатили, еще вчера, а на какую-то маленькую тестовую группу обратно закатили. Это, кстати, классно, потому что обычно все представляют, что АБ-тест – это что-то, когда мы наоборот тестируем, а тут мы наоборот отменяем и смотрим результат. Мы же тестируем, чтобы пользователей не обидеть, и тестируем какой-то маленькой группе. А если уже раскатили, можно провести обратный и сделать все правильно. Ну, а если все-таки глобальная ситуация? Ну, тогда рисуем два графика недели к неделю, берем линейку и смотрим, на сколько миллиметров, сантиметров вырос график. То есть здесь, в принципе, можно, получается, тоже статистически сравнивать просто, грубо говоря, эту же метрику с самой собой? Не статистически, а с линеечкой, скорее. Потому что неделя к неделе все будет краситься, и эффект сезонности всегда будет давать созначимые изменения, созначимые результаты. Тут так, на глаз, на 2%, на 3%. А какая у нас сезонность обычно, а какая сезонность сегодня. И если там вырос на 20%, то, скорее всего, что-то произошло. Понятно. Ну вот, кстати, с раскатом обратно прикольно. Я правильно понимаю, что это отчасти напоминает ухудшающий АБ-тест?\\n']}\n"
     ]
    }
   ],
   "source": [
    "for d in data:\n",
    "    print(d)\n",
    "\n",
    "# it is the way video json looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TextNode(id_='5c86129f-2559-4640-b908-c25b3da2ee60', embedding=None, metadata={'url': 'https://www.youtube.com/watch?v=Api2RW4ogR4', 'title': 'Зачем нужно проходить Симулятор ML? | karpov.courses'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e972e771-565e-4ee5-aa92-dabc94e8f857', node_type=None, metadata={'url': 'https://www.youtube.com/watch?v=Api2RW4ogR4', 'title': 'Зачем нужно проходить Симулятор ML? | karpov.courses'}, hash='94246086de32e9b3ec60cb60db5907d8bc7e38c15ce162e44b8b938a9039b29f')}, hash='c14d34bda85e6944f8cd02215a4fd7956cf71197785d02940eb79e0faa0f597c', text='Без опыта работы человека часто не берут на работу. А без работы ему часто не получается получить опыта на работе. Классический парадокс, бесконечная петля. Если вы думаете, что она возникает везде, но не в машинном обучении, то это не так. В подробнейшем большинстве обучающих курсов вам покажут, как обучать модели, как применять алгоритм. Вообще это не дает комплексного понимания того, чем же занимается инженер по машинному обучению. По факту есть куча чего до. От банального взять таску в тасктрекере, откуда-то данные выгрузить, куда-то их загрузить, какой-то стриминг настроить, потом обучить модель, применить ее к чему-то, а потом ее надо задеплоить или ее результат визуализировать, построить мониторинг, возможно провести АБТС. В общем, это куча всего. Это целый пайплайн, в котором еще можно много-много чего накидать. ML-симулятор призван как раз эту задачу решить. То есть это инфраструктура с задачами разного уровня. Вы туда приходите, понимаете, что вы сейчас уже можете сделать, а что вы делать не можете, пытаетесь это сделать, на этом учитесь и приобретаете этот комплексный охват. По окончанию симулятора вы можете уверенно сказать, я знаю, как решать эти задачи. Это вам поможет либо при приеме на работу, либо когда на работе у вас будет новая задача, будете знать, что с ней делать. Меня зовут Валерий Бабушкин, я хед в DataScience Blockchain.com и я приглашаю вас в симулятор инженера по машинному обучению.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " TextNode(id_='7002e54c-7bd2-4b2e-8883-9a16a1421d58', embedding=None, metadata={'url': 'https://www.youtube.com/watch?v=kYcA_RVDNWM', 'title': 'Redash display | Симулятор SQL | karpov.courses'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='a097a760-1940-4679-ab28-9070126a24ed', node_type=None, metadata={'url': 'https://www.youtube.com/watch?v=kYcA_RVDNWM', 'title': 'Redash display | Симулятор SQL | karpov.courses'}, hash='a541363aa5654ab5568e345c4af44b25ac7958903c8df3b6e855bfd943daae67'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='62351074-e1f7-4182-ae4a-eef577eff402', node_type=None, metadata={'url': 'https://www.youtube.com/watch?v=kYcA_RVDNWM', 'title': 'Redash display | Симулятор SQL | karpov.courses'}, hash='2b005d7ef9b4e5588be1d1e884a119d1bf57acfc4f96c48aa99a1b5f91f3ca4a')}, hash='ed732d08de81547007b0b2c03a5799506d458195493e7a28f857d3c11cc36192', text='Перед тем, как мы двинемся дальше, хотел бы еще пару слов сказать про Redash и про то, как он отображает данные. Важно понимать, что сами наши данные, как я уже говорил, хранятся в специальной базе данных в PostgreSQL, а Redash — это некоторый инструмент, который позволяет как писать запросы в базу данных, так и получать и смотреть на результат. И вот здесь скроется некоторый нюанс, потому что то, как Redash отображает результат, далеко не всегда совпадает с тем, как данные хранятся на самом деле и в каком-то смысле, как они на самом деле выглядят. Сейчас поясню, что я имею в виду. Давайте начнем с такого момента, как Redash отображает время. Если мы просто выгрузим несколько строчек из таблички orders, мы увидим, что у нас есть колоночка с временем создания заказа, и здесь мы видим, что формат довольно такой необычный. Соответственно, число, месяц и год разделены вот таким вот слэшем, а год записан только двумя последними цифрами. И вот это уже на самом деле то, как Redash отображает дату. Где-то в Redash есть настройка, что если он видит дату, то он сразу же переводит ее в такой формат. Наверное, вы видели, что, например, в том же самом Excel дату можно отображать довольно большим количеством в разных форматах. Сначала день, потом год, сначала год, потом день и так далее. То же самое в Redash. По умолчанию стоит вот такой формат отображения даты. При этом на самом деле дата хранится в более таком стандартном для анализа данных формате, где полностью сначала указывается год, месяц, день, и потом через пробелы двоеточия указывается, соответственно, минута, прошу прощения, часы, минуты и секунды. И вот обратите внимание, что это как раз-таки время второй, второго Order ID у нас, и Redash, допустим, секунды не отображает. Вот это вовсе не означает, что этих секунд нет на самом деле, это просто означает, что немножко вот так вот сокращает формат Redash. И забегая чуть вперед, если бы мы хотели отобрать, соответственно, запись, где у нас время, Creation Time вот такое, то вот такая вот форма записи у нас бы не сработала. Видите, мы бы вообще не вернули, прошу прощения, здесь я, да, ну, кстати, вот, была бы ошибка, что вообще как бы мы не смогли бы здесь так сравнить, и вот видите, здесь даже Redash нам сам бы написал, что скорее всего у нас в другом формате на самом деле хранится наше время. А если бы мы использовали для отбора нужных нам наблюдений время вот в таком формате, то все бы сработало. Мы чуть позже научимся уже отбирать нужные нам записи при помощи Wear, пока это просто демонстрация, которая основана для того, нужна для того, чтобы вы понимали, как на самом деле хранятся данные. И вот данные в самой базе данных в нашем постгрузе хранятся именно в таком формате. И когда вы дальше будете работать, например, с днями, чтобы отобрать только, допустим, 8 августа, 24 числа 2022 года, мы будем использовать запись именно вот такую.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " TextNode(id_='62351074-e1f7-4182-ae4a-eef577eff402', embedding=None, metadata={'url': 'https://www.youtube.com/watch?v=kYcA_RVDNWM', 'title': 'Redash display | Симулятор SQL | karpov.courses'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='a097a760-1940-4679-ab28-9070126a24ed', node_type=None, metadata={'url': 'https://www.youtube.com/watch?v=kYcA_RVDNWM', 'title': 'Redash display | Симулятор SQL | karpov.courses'}, hash='a541363aa5654ab5568e345c4af44b25ac7958903c8df3b6e855bfd943daae67'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='7002e54c-7bd2-4b2e-8883-9a16a1421d58', node_type=None, metadata={'url': 'https://www.youtube.com/watch?v=kYcA_RVDNWM', 'title': 'Redash display | Симулятор SQL | karpov.courses'}, hash='ed732d08de81547007b0b2c03a5799506d458195493e7a28f857d3c11cc36192'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='84d01643-d9c8-44f1-9249-8e10c5a9a243', node_type=None, metadata={'url': 'https://www.youtube.com/watch?v=kYcA_RVDNWM', 'title': 'Redash display | Симулятор SQL | karpov.courses'}, hash='8a387c2e3dcc3093625adbf31b4751a105d23424e02a211b72b932ba8b5f81d0')}, hash='2b005d7ef9b4e5588be1d1e884a119d1bf57acfc4f96c48aa99a1b5f91f3ca4a', text='Redash при этом, если мы выведем данные, он отобразит их немножко иначе, и он просто, во-первых, не станет отображать секунды, во-вторых, соответственно, здесь у нас не отобразятся полный год, допустим. Но это именно Redash так отображает данные, и нет ничего странного в этом, потому что это нормально. Существует довольно много инструментов, которые как-то у себя в своем типе визуализации немного как-то там используют свои форматы. И вы на работе можете работать не в Redash, а в каких-нибудь других системах для написания запросов, и, возможно, они тоже будут как-то немножко форматировать результаты под себя. Нужно просто понимать, что зачастую формат, который хранится в самих данных, и формат, который отображается, он может различаться. Второй пример тоже довольно показательный. Давайте, например, представим, что у нас задача посчитать среднее количество заказов на пользователя. У нас было 10, соответственно, заказов и, соответственно, 7 пользователей. Если мы посчитаем вот эту вот, прошу прощения, здесь просто select. Если мы посчитаем вот такую вот запись, то мы получим 1,43. И можно подумать, как будто у нас только два знака после запятой. Но если бы мы, на самом деле, допустим, вот скачали бы наш результат, такой CSV-файлик, и посмотрели бы, что вот там получилось, то мы бы увидели, что после запятой вы видите довольно много знаков в том числе. В этом смысле Redash просто, как только видит числа, у которых есть знаки после запятой, округляет до двух. И если бы в задаче вас просили бы посчитайте, например, вот orders per user, и округлите до двух знаков после запятой, вы бы сделали какой-то такой запросик и посмотрели бы, о, у меня уже до двух знаков округлено, отлично. И отправили бы на проверку, то, возможно, вы могли бы получить ошибку. Надо более явно округлить до двух знаков после запятой, и теперь это уже будет верный ответ. При этом обратите внимание, что с точки зрения Redash вот эти две записи, они никак не отличаются. Что 10 деленное на 7, что round 10 деленное на 7. Но это только потому, что Redash просто сам у себя вот на этом фронтенде своем уже, соответственно, округляет немножко до двух знаков только после запятой. Вот, это просто важно помнить, что в задачках, например, вас часто будут просить округлить какую-нибудь метрику до двух знаков, и если вы увидите, что у вас в Redash как будто уже округлено, не верьте ему, на самом деле сделайте еще раз round, потому что на самом деле вы как бы отправите в нашу систему проверки не округленный до двух знаков, не соответственно не 1, там, да, 43, а вот 1, 42, 8, 5, 7 и так далее. И может не пройтись просто проверка на правильность. Вот, это два таких важных нюанса. Соответственно, важно понимать, что Redash может хранить данные немного иначе, чем это выглядит. И тоже, забегая уже вперед, мы на самом деле потом с вами научимся смотреть на то, как данные выглядят на самом деле.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " TextNode(id_='84d01643-d9c8-44f1-9249-8e10c5a9a243', embedding=None, metadata={'url': 'https://www.youtube.com/watch?v=kYcA_RVDNWM', 'title': 'Redash display | Симулятор SQL | karpov.courses'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='a097a760-1940-4679-ab28-9070126a24ed', node_type=None, metadata={'url': 'https://www.youtube.com/watch?v=kYcA_RVDNWM', 'title': 'Redash display | Симулятор SQL | karpov.courses'}, hash='a541363aa5654ab5568e345c4af44b25ac7958903c8df3b6e855bfd943daae67'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='62351074-e1f7-4182-ae4a-eef577eff402', node_type=None, metadata={'url': 'https://www.youtube.com/watch?v=kYcA_RVDNWM', 'title': 'Redash display | Симулятор SQL | karpov.courses'}, hash='2b005d7ef9b4e5588be1d1e884a119d1bf57acfc4f96c48aa99a1b5f91f3ca4a')}, hash='8a387c2e3dcc3093625adbf31b4751a105d23424e02a211b72b932ba8b5f81d0', text='Вот здесь, вот в этом примере, например, Orders, тоже всегда можно было бы посмотреть, как у нас выглядит колоночка Creation Time, если бы мы просто перевели ее формат текстовый. Текстовый формат Redash уже никак не, соответственно, форматирует, и вот мы могли бы убедиться, что на самом деле вот в таком формате хранится у нас с вами эта запись. И в справедливости ради, если бы мы 10, деленное на 7, тоже перевели бы в текстовый формат, мы бы увидели, что там сильно больше знаков после запятой, прошу прощения, сильно больше знаков после запятой, потому что, опять же, это просто уже Redash округлил нам это число, а на самом деле там сильно больше знаков. Вот, это два таких нюанса, и при этом, как я уже сказал, что ладно бы, если это было исключительно там просто только для курса важно, но в каком-то смысле и на реальной работе вы сможете столкнуться с тем, что если вы подумаете, допустим, что здесь у вас там уже округление произведено, а для каких-то дальнейших вычислений, вот для какой-то работы там целого пайплайна аналитического все-таки довольно важно, чтобы, например, аналитик выдавал какие-то значения, округленные до двух знаков, то вы должны в своем коде явно прописывать округление уже, соответственно, при помощи функции, а не доверяя тому, что просто Redash сам округляет для более удобного восприятия. Вот такая вот важная история, надеюсь, она пригодится вам при решении наших задачек и в работе может реально пригодиться и сэкономит вам, возможно, время для поиска ошибки, когда вы думаете, что там у вас уже округлено до двух знаков, а на самом деле просто, соответственно, этот Redash так сделал. Или когда в примере ожидаемого результата написана дата в формате 2022.1409, а Redash возвращает через эти слэши, и вы думаете, как бы мне там срочно переформатировать формат даты. Ничего страшного, просто помните, что на самом деле это Redash немного так подкручивает у себя чисто визуально данные, и просто можете теперь более аккуратно решать наши задачки.', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'),\n",
       " TextNode(id_='549c9516-c8d9-432e-a3df-cc1fb928d7c4', embedding=None, metadata={'url': 'https://www.youtube.com/watch?v=NcDcxOqB52k', 'title': 'Об A/B тестах без A/B тестов | Никита Маршалкин | karpov.courses'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='ac8906f2-8f66-4442-a9c8-5acc7b90625d', node_type=None, metadata={'url': 'https://www.youtube.com/watch?v=NcDcxOqB52k', 'title': 'Об A/B тестах без A/B тестов | Никита Маршалкин | karpov.courses'}, hash='2ea480b096939476af3eebb56864dd1159469b83ec77d5249943753ece9dc700')}, hash='0b0aa04df7604b054cd4a400313a252b656f27efad959982fa0387fbf962029a', text='Моя любимая рубрика — это АБ-эксперименты без АБ-экспериментов. Сейчас поясню, что я имею в виду. На практике иногда происходят события, которые никак не предугадать. Вот случился ковид. И сразу все стали бросаться смотреть на графики, как ковид на что-нибудь повлиял. Вот, например, классический такой график. Как ковид повлиял, например, на показы рекламы мобильных игр в ленте. И вот мы видим, что что-то подросло. Понятное дело, что тяжело провести АБ-тест с вопросом, как ковид влияет на показы АБ-тестов. Как минимум, звучит не очень этично. Как ковид влияет на показы рекламы. И на самом деле на практике, на моей практике, это тоже очень частый вопрос. Прибегают какие-то продукты, менеджеры, другие отделы. Говорят, Толя, уже вчера выкатили. АБ-тест нужно было провести позавчера, поэтому сорян. Вот смотри, вот мы выкатили, и вот что-то поросло-падало. Что делать в таких ситуациях? Знаешь, такая классическая методология научная говорит, что ничего. Это псевдоэксперимент, все, никаких выводов сделать нельзя. На практике не очень полезный ответ. То есть ковид действительно либо повлиял, либо не повлиял. Как можно этот график интерпретировать и попробовать сделать какой-то статвывод все-таки? Если откатиться немножко, если уже выкатили, то можно закатить обратно. Взять маленькую группу пользователей. Это, кстати, интересный поинт. И провести не прямой эксперимент, когда мы на большом количестве контроль и на маленькой мы тестируем гипотезу, а провести обратный эксперимент, когда мы на всех уже раскатили, еще вчера, а на какую-то маленькую тестовую группу обратно закатили. Это, кстати, классно, потому что обычно все представляют, что АБ-тест – это что-то, когда мы наоборот тестируем, а тут мы наоборот отменяем и смотрим результат. Мы же тестируем, чтобы пользователей не обидеть, и тестируем какой-то маленькой группе. А если уже раскатили, можно провести обратный и сделать все правильно. Ну, а если все-таки глобальная ситуация? Ну, тогда рисуем два графика недели к неделю, берем линейку и смотрим, на сколько миллиметров, сантиметров вырос график. То есть здесь, в принципе, можно, получается, тоже статистически сравнивать просто, грубо говоря, эту же метрику с самой собой? Не статистически, а с линеечкой, скорее. Потому что неделя к неделе все будет краситься, и эффект сезонности всегда будет давать созначимые изменения, созначимые результаты. Тут так, на глаз, на 2%, на 3%. А какая у нас сезонность обычно, а какая сезонность сегодня. И если там вырос на 20%, то, скорее всего, что-то произошло. Понятно. Ну вот, кстати, с раскатом обратно прикольно. Я правильно понимаю, что это отчасти напоминает ухудшающий АБ-тест?', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nodes\n",
    "\n",
    "# our nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'5c86129f-2559-4640-b908-c25b3da2ee60': 'https://www.youtube.com/watch?v=Api2RW4ogR4',\n",
       " '7002e54c-7bd2-4b2e-8883-9a16a1421d58': 'https://www.youtube.com/watch?v=kYcA_RVDNWM',\n",
       " '62351074-e1f7-4182-ae4a-eef577eff402': 'https://www.youtube.com/watch?v=kYcA_RVDNWM',\n",
       " '84d01643-d9c8-44f1-9249-8e10c5a9a243': 'https://www.youtube.com/watch?v=kYcA_RVDNWM',\n",
       " '549c9516-c8d9-432e-a3df-cc1fb928d7c4': 'https://www.youtube.com/watch?v=NcDcxOqB52k'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. pairs node id: original video url\n",
    "\n",
    "node_connector = {node.id_: node.metadata['url'] for node in nodes}\n",
    "node_connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have connection node_id - video url. let's use it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now connect question id to its node id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'80ffe444-7500-42a3-9bb3-5580dd745125': '5c86129f-2559-4640-b908-c25b3da2ee60',\n",
       " '1102533d-17ad-43ce-8b1b-04fa8b76c1e8': '7002e54c-7bd2-4b2e-8883-9a16a1421d58',\n",
       " 'a60f0d8d-4dd3-4dc2-a233-2b5c9223fe1a': '62351074-e1f7-4182-ae4a-eef577eff402',\n",
       " '97d90959-ee63-456e-8d55-1067d8180a2a': '84d01643-d9c8-44f1-9249-8e10c5a9a243',\n",
       " 'c822a435-6d44-4dca-bd5d-5c05014ec15d': '549c9516-c8d9-432e-a3df-cc1fb928d7c4'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. pairs question id: node id\n",
    "\n",
    "question_connector = {question_id: qa_dataset.relevant_docs[question_id][0] for question_id in qa_dataset.relevant_docs}\n",
    "question_connector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now connect question id to its video url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'80ffe444-7500-42a3-9bb3-5580dd745125': 'https://www.youtube.com/watch?v=Api2RW4ogR4',\n",
       " '1102533d-17ad-43ce-8b1b-04fa8b76c1e8': 'https://www.youtube.com/watch?v=kYcA_RVDNWM',\n",
       " 'a60f0d8d-4dd3-4dc2-a233-2b5c9223fe1a': 'https://www.youtube.com/watch?v=kYcA_RVDNWM',\n",
       " '97d90959-ee63-456e-8d55-1067d8180a2a': 'https://www.youtube.com/watch?v=kYcA_RVDNWM',\n",
       " 'c822a435-6d44-4dca-bd5d-5c05014ec15d': 'https://www.youtube.com/watch?v=NcDcxOqB52k'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. pairs question id: url\n",
    "\n",
    "question_id_url = {question_id: node_connector[question_connector[question_id]] for question_id in question_connector}\n",
    "\n",
    "question_id_url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "revert the pairs to have a dict of {video url: [question_ids]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://www.youtube.com/watch?v=Api2RW4ogR4': ['80ffe444-7500-42a3-9bb3-5580dd745125'],\n",
       " 'https://www.youtube.com/watch?v=kYcA_RVDNWM': ['1102533d-17ad-43ce-8b1b-04fa8b76c1e8',\n",
       "  'a60f0d8d-4dd3-4dc2-a233-2b5c9223fe1a',\n",
       "  '97d90959-ee63-456e-8d55-1067d8180a2a'],\n",
       " 'https://www.youtube.com/watch?v=NcDcxOqB52k': ['c822a435-6d44-4dca-bd5d-5c05014ec15d']}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. pairs url: question id (in a list)\n",
    "url_question_id = {}\n",
    "\n",
    "for key, value in question_id_url.items():\n",
    "    if value in url_question_id:\n",
    "        url_question_id[value].append(key)\n",
    "    else:\n",
    "        url_question_id[value] = [key]\n",
    "\n",
    "url_question_id\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "replace question ids by their text values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://www.youtube.com/watch?v=Api2RW4ogR4': ['Какие задачи решает ML-симулятор и как он помогает инженерам по машинному обучению при приеме на работу и в работе?'],\n",
       " 'https://www.youtube.com/watch?v=kYcA_RVDNWM': ['Как Redash отображает дату и время в своих результатных данных и как они хранятся в базе данных PostgreSQL?',\n",
       "  'Как Redash отображает данные и как это может повлиять на результаты анализа данных?',\n",
       "  'Какие нюансы и проблемы могут возникнуть при работе с данными в Redash, связанные с форматированием чисел и дат?'],\n",
       " 'https://www.youtube.com/watch?v=NcDcxOqB52k': ['Как можно использовать обратный эксперимент и сравнение графиков для анализа влияния ковида на показы рекламы мобильных игр?']}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. url: questions\n",
    "\n",
    "url_question = {url: [qa_dataset.queries[question_id] for question_id in url_question_id[url]] for url in url_question_id}\n",
    "\n",
    "url_question\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modify the original video json - append question pairs to each video dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 extend the original json\n",
    "\n",
    "for video in data:\n",
    "    video['control_questions'] = url_question[video['url'][0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "thats how video json looks now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': ['https://www.youtube.com/watch?v=Api2RW4ogR4'],\n",
       "  'title': ['Зачем нужно проходить Симулятор ML? | karpov.courses'],\n",
       "  'description': ['Симулятор ML: https://bit.ly/3E4jQos\\n\\nНа старте карьеры многие из нас попадали в замкнутый круг «чтобы получить работу – нужно показать опыт; чтобы получить опыт – нужно, чтобы тебя взяли на работу». Как его разорвать? Найти стажировку? Сделать свой пет-проект?.. \\n\\nМы решили помочь вырваться из этого парадокса и создали симулятор инженера по машинному обучению. Здесь вы научитесь решать задачи, с которыми инженеры сталкиваются ежедневно. Уже в первые месяцы тренировок вы подружитесь со всеми необходимыми для работы инструментами, начнёте понимать полный цикл построения ML-систем и узнаете, как с помощью машинного обучения приносить бизнесу прибыль, что повысит вашу ценность для компании.'],\n",
       "  'audio_path': ['../data/audio/Api2RW4ogR4.mp4'],\n",
       "  'text': ['Без опыта работы человека часто не берут на работу. А без работы ему часто не получается получить опыта на работе. Классический парадокс, бесконечная петля. Если вы думаете, что она возникает везде, но не в машинном обучении, то это не так. В подробнейшем большинстве обучающих курсов вам покажут, как обучать модели, как применять алгоритм. Вообще это не дает комплексного понимания того, чем же занимается инженер по машинному обучению. По факту есть куча чего до. От банального взять таску в тасктрекере, откуда-то данные выгрузить, куда-то их загрузить, какой-то стриминг настроить, потом обучить модель, применить ее к чему-то, а потом ее надо задеплоить или ее результат визуализировать, построить мониторинг, возможно провести АБТС. В общем, это куча всего. Это целый пайплайн, в котором еще можно много-много чего накидать. ML-симулятор призван как раз эту задачу решить. То есть это инфраструктура с задачами разного уровня. Вы туда приходите, понимаете, что вы сейчас уже можете сделать, а что вы делать не можете, пытаетесь это сделать, на этом учитесь и приобретаете этот комплексный охват. По окончанию симулятора вы можете уверенно сказать, я знаю, как решать эти задачи. Это вам поможет либо при приеме на работу, либо когда на работе у вас будет новая задача, будете знать, что с ней делать. Меня зовут Валерий Бабушкин, я хед в DataScience Blockchain.com и я приглашаю вас в симулятор инженера по машинному обучению.\\n'],\n",
       "  'control_questions': ['Какие задачи решает ML-симулятор и как он помогает инженерам по машинному обучению при приеме на работу и в работе?']},\n",
       " {'url': ['https://www.youtube.com/watch?v=kYcA_RVDNWM'],\n",
       "  'title': ['Redash display | Симулятор SQL | karpov.courses'],\n",
       "  'description': ['Урок: https://lab.karpov.courses/learning/152/module/1762/lesson/18484/53200/269826/\\nСимулятор SQL: https://bit.ly/3XDroX0'],\n",
       "  'audio_path': ['../data/audio/kYcA_RVDNWM.mp4'],\n",
       "  'text': ['Перед тем, как мы двинемся дальше, хотел бы еще пару слов сказать про Redash и про то, как он отображает данные. Важно понимать, что сами наши данные, как я уже говорил, хранятся в специальной базе данных в PostgreSQL, а Redash — это некоторый инструмент, который позволяет как писать запросы в базу данных, так и получать и смотреть на результат. И вот здесь скроется некоторый нюанс, потому что то, как Redash отображает результат, далеко не всегда совпадает с тем, как данные хранятся на самом деле и в каком-то смысле, как они на самом деле выглядят. Сейчас поясню, что я имею в виду. Давайте начнем с такого момента, как Redash отображает время. Если мы просто выгрузим несколько строчек из таблички orders, мы увидим, что у нас есть колоночка с временем создания заказа, и здесь мы видим, что формат довольно такой необычный. Соответственно, число, месяц и год разделены вот таким вот слэшем, а год записан только двумя последними цифрами. И вот это уже на самом деле то, как Redash отображает дату. Где-то в Redash есть настройка, что если он видит дату, то он сразу же переводит ее в такой формат. Наверное, вы видели, что, например, в том же самом Excel дату можно отображать довольно большим количеством в разных форматах. Сначала день, потом год, сначала год, потом день и так далее. То же самое в Redash. По умолчанию стоит вот такой формат отображения даты. При этом на самом деле дата хранится в более таком стандартном для анализа данных формате, где полностью сначала указывается год, месяц, день, и потом через пробелы двоеточия указывается, соответственно, минута, прошу прощения, часы, минуты и секунды. И вот обратите внимание, что это как раз-таки время второй, второго Order ID у нас, и Redash, допустим, секунды не отображает. Вот это вовсе не означает, что этих секунд нет на самом деле, это просто означает, что немножко вот так вот сокращает формат Redash. И забегая чуть вперед, если бы мы хотели отобрать, соответственно, запись, где у нас время, Creation Time вот такое, то вот такая вот форма записи у нас бы не сработала. Видите, мы бы вообще не вернули, прошу прощения, здесь я, да, ну, кстати, вот, была бы ошибка, что вообще как бы мы не смогли бы здесь так сравнить, и вот видите, здесь даже Redash нам сам бы написал, что скорее всего у нас в другом формате на самом деле хранится наше время. А если бы мы использовали для отбора нужных нам наблюдений время вот в таком формате, то все бы сработало. Мы чуть позже научимся уже отбирать нужные нам записи при помощи Wear, пока это просто демонстрация, которая основана для того, нужна для того, чтобы вы понимали, как на самом деле хранятся данные. И вот данные в самой базе данных в нашем постгрузе хранятся именно в таком формате. И когда вы дальше будете работать, например, с днями, чтобы отобрать только, допустим, 8 августа, 24 числа 2022 года, мы будем использовать запись именно вот такую. Redash при этом, если мы выведем данные, он отобразит их немножко иначе, и он просто, во-первых, не станет отображать секунды, во-вторых, соответственно, здесь у нас не отобразятся полный год, допустим. Но это именно Redash так отображает данные, и нет ничего странного в этом, потому что это нормально. Существует довольно много инструментов, которые как-то у себя в своем типе визуализации немного как-то там используют свои форматы. И вы на работе можете работать не в Redash, а в каких-нибудь других системах для написания запросов, и, возможно, они тоже будут как-то немножко форматировать результаты под себя. Нужно просто понимать, что зачастую формат, который хранится в самих данных, и формат, который отображается, он может различаться. Второй пример тоже довольно показательный. Давайте, например, представим, что у нас задача посчитать среднее количество заказов на пользователя. У нас было 10, соответственно, заказов и, соответственно, 7 пользователей. Если мы посчитаем вот эту вот, прошу прощения, здесь просто select. Если мы посчитаем вот такую вот запись, то мы получим 1,43. И можно подумать, как будто у нас только два знака после запятой. Но если бы мы, на самом деле, допустим, вот скачали бы наш результат, такой CSV-файлик, и посмотрели бы, что вот там получилось, то мы бы увидели, что после запятой вы видите довольно много знаков в том числе. В этом смысле Redash просто, как только видит числа, у которых есть знаки после запятой, округляет до двух. И если бы в задаче вас просили бы посчитайте, например, вот orders per user, и округлите до двух знаков после запятой, вы бы сделали какой-то такой запросик и посмотрели бы, о, у меня уже до двух знаков округлено, отлично. И отправили бы на проверку, то, возможно, вы могли бы получить ошибку. Надо более явно округлить до двух знаков после запятой, и теперь это уже будет верный ответ. При этом обратите внимание, что с точки зрения Redash вот эти две записи, они никак не отличаются. Что 10 деленное на 7, что round 10 деленное на 7. Но это только потому, что Redash просто сам у себя вот на этом фронтенде своем уже, соответственно, округляет немножко до двух знаков только после запятой. Вот, это просто важно помнить, что в задачках, например, вас часто будут просить округлить какую-нибудь метрику до двух знаков, и если вы увидите, что у вас в Redash как будто уже округлено, не верьте ему, на самом деле сделайте еще раз round, потому что на самом деле вы как бы отправите в нашу систему проверки не округленный до двух знаков, не соответственно не 1, там, да, 43, а вот 1, 42, 8, 5, 7 и так далее. И может не пройтись просто проверка на правильность. Вот, это два таких важных нюанса. Соответственно, важно понимать, что Redash может хранить данные немного иначе, чем это выглядит. И тоже, забегая уже вперед, мы на самом деле потом с вами научимся смотреть на то, как данные выглядят на самом деле. Вот здесь, вот в этом примере, например, Orders, тоже всегда можно было бы посмотреть, как у нас выглядит колоночка Creation Time, если бы мы просто перевели ее формат текстовый. Текстовый формат Redash уже никак не, соответственно, форматирует, и вот мы могли бы убедиться, что на самом деле вот в таком формате хранится у нас с вами эта запись. И в справедливости ради, если бы мы 10, деленное на 7, тоже перевели бы в текстовый формат, мы бы увидели, что там сильно больше знаков после запятой, прошу прощения, сильно больше знаков после запятой, потому что, опять же, это просто уже Redash округлил нам это число, а на самом деле там сильно больше знаков. Вот, это два таких нюанса, и при этом, как я уже сказал, что ладно бы, если это было исключительно там просто только для курса важно, но в каком-то смысле и на реальной работе вы сможете столкнуться с тем, что если вы подумаете, допустим, что здесь у вас там уже округление произведено, а для каких-то дальнейших вычислений, вот для какой-то работы там целого пайплайна аналитического все-таки довольно важно, чтобы, например, аналитик выдавал какие-то значения, округленные до двух знаков, то вы должны в своем коде явно прописывать округление уже, соответственно, при помощи функции, а не доверяя тому, что просто Redash сам округляет для более удобного восприятия. Вот такая вот важная история, надеюсь, она пригодится вам при решении наших задачек и в работе может реально пригодиться и сэкономит вам, возможно, время для поиска ошибки, когда вы думаете, что там у вас уже округлено до двух знаков, а на самом деле просто, соответственно, этот Redash так сделал. Или когда в примере ожидаемого результата написана дата в формате 2022.1409, а Redash возвращает через эти слэши, и вы думаете, как бы мне там срочно переформатировать формат даты. Ничего страшного, просто помните, что на самом деле это Redash немного так подкручивает у себя чисто визуально данные, и просто можете теперь более аккуратно решать наши задачки.\\n'],\n",
       "  'control_questions': ['Как Redash отображает дату и время в своих результатных данных и как они хранятся в базе данных PostgreSQL?',\n",
       "   'Как Redash отображает данные и как это может повлиять на результаты анализа данных?',\n",
       "   'Какие нюансы и проблемы могут возникнуть при работе с данными в Redash, связанные с форматированием чисел и дат?']},\n",
       " {'url': ['https://www.youtube.com/watch?v=NcDcxOqB52k'],\n",
       "  'title': ['Об A/B тестах без A/B тестов | Никита Маршалкин | karpov.courses'],\n",
       "  'description': ['Симулятор A/B-тестов: http://bit.ly/3ZQCp7t \\n\\nСмотрите полное интервью по ссылке: https://youtu.be/gljfGAkgX_o\\n\\nУчитесь Data Science с нами: https://karpov.courses/'],\n",
       "  'audio_path': ['../data/audio/NcDcxOqB52k.mp4'],\n",
       "  'text': ['Моя любимая рубрика — это АБ-эксперименты без АБ-экспериментов. Сейчас поясню, что я имею в виду. На практике иногда происходят события, которые никак не предугадать. Вот случился ковид. И сразу все стали бросаться смотреть на графики, как ковид на что-нибудь повлиял. Вот, например, классический такой график. Как ковид повлиял, например, на показы рекламы мобильных игр в ленте. И вот мы видим, что что-то подросло. Понятное дело, что тяжело провести АБ-тест с вопросом, как ковид влияет на показы АБ-тестов. Как минимум, звучит не очень этично. Как ковид влияет на показы рекламы. И на самом деле на практике, на моей практике, это тоже очень частый вопрос. Прибегают какие-то продукты, менеджеры, другие отделы. Говорят, Толя, уже вчера выкатили. АБ-тест нужно было провести позавчера, поэтому сорян. Вот смотри, вот мы выкатили, и вот что-то поросло-падало. Что делать в таких ситуациях? Знаешь, такая классическая методология научная говорит, что ничего. Это псевдоэксперимент, все, никаких выводов сделать нельзя. На практике не очень полезный ответ. То есть ковид действительно либо повлиял, либо не повлиял. Как можно этот график интерпретировать и попробовать сделать какой-то статвывод все-таки? Если откатиться немножко, если уже выкатили, то можно закатить обратно. Взять маленькую группу пользователей. Это, кстати, интересный поинт. И провести не прямой эксперимент, когда мы на большом количестве контроль и на маленькой мы тестируем гипотезу, а провести обратный эксперимент, когда мы на всех уже раскатили, еще вчера, а на какую-то маленькую тестовую группу обратно закатили. Это, кстати, классно, потому что обычно все представляют, что АБ-тест – это что-то, когда мы наоборот тестируем, а тут мы наоборот отменяем и смотрим результат. Мы же тестируем, чтобы пользователей не обидеть, и тестируем какой-то маленькой группе. А если уже раскатили, можно провести обратный и сделать все правильно. Ну, а если все-таки глобальная ситуация? Ну, тогда рисуем два графика недели к неделю, берем линейку и смотрим, на сколько миллиметров, сантиметров вырос график. То есть здесь, в принципе, можно, получается, тоже статистически сравнивать просто, грубо говоря, эту же метрику с самой собой? Не статистически, а с линеечкой, скорее. Потому что неделя к неделе все будет краситься, и эффект сезонности всегда будет давать созначимые изменения, созначимые результаты. Тут так, на глаз, на 2%, на 3%. А какая у нас сезонность обычно, а какая сезонность сегодня. И если там вырос на 20%, то, скорее всего, что-то произошло. Понятно. Ну вот, кстати, с раскатом обратно прикольно. Я правильно понимаю, что это отчасти напоминает ухудшающий АБ-тест?\\n'],\n",
       "  'control_questions': ['Как можно использовать обратный эксперимент и сравнение графиков для анализа влияния ковида на показы рекламы мобильных игр?']}]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump the final json\n",
    "\n",
    "with open('video_info_test_with_questions.json', \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now wrap it to a function `question_gen` will be used in `evalutate_utils.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.schema import BaseNode\n",
    "\n",
    "# parse json file with transcribed videos\n",
    "# and save a modified file\n",
    "import json\n",
    "\n",
    "# to pass the model object into the functions\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "# initialize the Document object to be used by SimpleNodeParser\n",
    "from llama_index import Document\n",
    "\n",
    "# to split the video text into the nodes\n",
    "from llama_index.node_parser import SimpleNodeParser\n",
    "\n",
    "# make node: question pairs\n",
    "from llama_index.evaluation import generate_question_context_pairs\n",
    "\n",
    "\n",
    "def process_nodes(nodes: List[BaseNode]) -> List[BaseNode]:\n",
    "    \"\"\"\n",
    "    Processes a list of nodes based on the following criteria:\n",
    "    \n",
    "    1. If a node has the same title as the previous one, it's added to the result list \n",
    "       only if its word count is more than 50% of the previous node's word count.\n",
    "    2. If a node has a different title, it's simply added to the result list.\n",
    "\n",
    "    Parameters:\n",
    "    - nodes (list): A list of BaseNode objects.\n",
    "\n",
    "    Returns:\n",
    "    - list: A processed list of BaseNode objects.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initialize an empty list to store the processed nodes\n",
    "    result = []\n",
    "\n",
    "    # Initialize variables to keep track of the previous node's title and word count\n",
    "    prev_title = None\n",
    "    prev_word_count = 0\n",
    "\n",
    "    # Iterate through the list of nodes\n",
    "    for node in nodes:\n",
    "        current_title = node.metadata['title']\n",
    "        current_word_count = len(node.text.split())\n",
    "\n",
    "        # Check if the current node has the same title as the previous one\n",
    "        if current_title == prev_title:\n",
    "            if current_word_count > 0.5 * prev_word_count:\n",
    "                result.append(node)\n",
    "        else:\n",
    "            result.append(node)\n",
    "\n",
    "        # Update the previous title and word count for the next iteration\n",
    "        prev_title = current_title\n",
    "        prev_word_count = current_word_count\n",
    "\n",
    "    return result\n",
    "\n",
    "def generate_video_questions(\n",
    "        video_info_path: str,\n",
    "        llm: OpenAI,\n",
    "        chunk_size: int = 3 * 1024,\n",
    "        video_info_output_path: str = None,\n",
    "        test_version: bool = True\n",
    "        ) -> None:\n",
    "    \"\"\"\n",
    "    Генерирует вопросы к тексту каждого видео из video_info.json, разбивая текст предварительно\n",
    "    на 'chunk_size' токенов. Сохраняет сгенерированные вопросы в video_info.json.\n",
    "    Шаблон получившегося video_info.json:\n",
    "    [\n",
    "        {\n",
    "            \"url\": [<url of video>],\n",
    "            \"title\": [<title of video>],\n",
    "            \"description\": [<description of video>],\n",
    "            \"audio_path\": [<path to audio track of video>],\n",
    "            \"text\": [<text of video>],\n",
    "            \"control_questions\": [<generated questions>]\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    video_info_path: str\n",
    "        path to video_info.json\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # create an output json path\n",
    "    if not video_info_output_path:\n",
    "        video_info_output_path = video_info_path.replace('.json', '_with_questions.json')\n",
    "\n",
    "    # open json with transcribed videos and parse\n",
    "    with open(video_info_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        video_json = json.load(f)\n",
    "\n",
    "    # when testing, do not run the function on thr whole json dataset\n",
    "    if test_version:\n",
    "        video_json = video_json[:3]\n",
    "\n",
    "    assert len(video_json) == 3\n",
    "\n",
    "    # a list of Documents to be used by SimpleNodeParser\n",
    "    # to make a list of Nodes\n",
    "    docs = [\n",
    "        Document(\n",
    "            text=\"\".join(video_dict[\"text\"]),\n",
    "            metadata={\"url\": video_dict[\"url\"][0], \"title\": video_dict[\"title\"][0]},\n",
    "        )\n",
    "        for video_dict in video_json\n",
    "    ]\n",
    "\n",
    "    # parse the docs into the nodes\n",
    "    parser = SimpleNodeParser.from_defaults(chunk_size=chunk_size)\n",
    "    nodes = parser.get_nodes_from_documents(docs)\n",
    "\n",
    "    # process the nodes to discard the last node of the video \n",
    "    # if it is very shortened during splitting\n",
    "    nodes = process_nodes(nodes)\n",
    "\n",
    "    # make a prompt template\n",
    "    qa_generate_prompt_tmpl = \"\"\"\\\n",
    "    Внизу указана контекстная информация.\n",
    "\n",
    "    ---------------------\n",
    "    {context_str}\n",
    "    ---------------------\n",
    "\n",
    "    На основе приведенного текста составь только один вопрос, \\\n",
    "    на который можно ответить с помощью текста. \\\n",
    "    Вопрос должен покрыть как можно больше аспектов в тексте. \\\n",
    "    Он должен быть только на основе привденного текста \\\n",
    "    и относиться к области анализа данных.\"\n",
    "    \"\"\"\n",
    "\n",
    "    # query based on the nodes list\n",
    "    # num_questions_per_chunk will anyway not appear in the query, \n",
    "    # can be any value :)\n",
    "    qa_dataset = generate_question_context_pairs(\n",
    "        nodes=nodes, \n",
    "        llm=llm, \n",
    "        qa_generate_prompt_tmpl=qa_generate_prompt_tmpl,\n",
    "        num_questions_per_chunk=1 \n",
    "        )\n",
    "\n",
    "    # pairs node_id: video_url\n",
    "    node_id_url = {node.id_: node.metadata['url'] for node in nodes}\n",
    "\n",
    "    # pairs question_id: node_id\n",
    "    question_id_node_id = {\n",
    "        question_id: qa_dataset.relevant_docs[question_id][0] \n",
    "        for question_id in qa_dataset.relevant_docs\n",
    "        }\n",
    "    \n",
    "    # pairs question_id: video_url\n",
    "    question_id_url = {\n",
    "        question_id: node_id_url[question_id_node_id[question_id]] \n",
    "        for question_id in question_id_node_id\n",
    "        }\n",
    "    \n",
    "    # invert the 'question_id_url'\n",
    "    # pairs video_url: list[question_id]\n",
    "    url_question_id = {}\n",
    "\n",
    "    for key, value in question_id_url.items():\n",
    "        if value in url_question_id:\n",
    "            url_question_id[value].append(key)\n",
    "        else:\n",
    "            url_question_id[value] = [key]\n",
    "    \n",
    "    # replace question_id by question_text\n",
    "    # pairs video_url: list[question]\n",
    "\n",
    "    url_question = {\n",
    "        url: [\n",
    "            qa_dataset.queries[question_id] \n",
    "              for question_id in url_question_id[url]\n",
    "              ] \n",
    "              for url in url_question_id\n",
    "              }\n",
    "    \n",
    "    # extend the original json\n",
    "    # by creating 'control_questions': list[question] pairs\n",
    "    # for each video's dict\n",
    "    for video_dict in video_json:\n",
    "        video_dict['control_questions'] = url_question[video_dict['url'][0]]\n",
    "    \n",
    "    # dump the final json to a new file\n",
    "    with open(video_info_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(video_json, f, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:12<00:00,  2.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# make the async code working in the notebook cells\n",
    "import nest_asyncio\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# get the API key to the variable\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# initialize the model\n",
    "gpt3 = OpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "generate_video_questions(\n",
    "        video_info_path='../data/video_info.json',\n",
    "        llm=gpt3,\n",
    "        chunk_size = 3 * 1024,\n",
    "        test_version=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 1 - сносно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Какие задачи можно решить с помощью ML-симулятора?',\n",
       " 'Какие данные хранятся в базе данных PostgreSQL?']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_gen_query = \"Ты - начинающий спецалист в анализе данных. \\\n",
    "                        На основе приведенного текста составь только один вопрос, \\\n",
    "                        на который можно ответить с помощью текста. \\\n",
    "                        Вопрос должен покрыть как можно больше аспектов в тексте. \\\n",
    "                        Он должен быть только на основе привденного текста \\\n",
    "                        и относиться к области анализа данных\" \n",
    "\n",
    "data_generator_nodes = DatasetGenerator(\n",
    "    nodes=nodes[:2],\n",
    "    service_context=service_context_gpt3,\n",
    "    question_gen_query=question_gen_query\n",
    "    )\n",
    "\n",
    "eval_questions_nodes = data_generator_nodes.generate_questions_from_nodes()\n",
    "\n",
    "eval_questions_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 2 - лучший"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Какие задачи решает ML-симулятор и как он помогает инженеру по машинному обучению?',\n",
       " 'Какие важные нюансы нужно учитывать при хранении данных в Redash и как это может повлиять на аналитический анализ данных?']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_gen_query = \"На основе приведенного текста составь только один вопрос, \\\n",
    "                        на который можно ответить с помощью текста. \\\n",
    "                        Вопрос должен покрыть как можно больше аспектов в тексте. \\\n",
    "                        Он должен быть только на основе привденного текста \\\n",
    "                        и относиться к области анализа данных\" \n",
    "\n",
    "data_generator_nodes = DatasetGenerator(\n",
    "    nodes=nodes[:2],\n",
    "    service_context=service_context_gpt3,\n",
    "    question_gen_query=question_gen_query\n",
    "    )\n",
    "\n",
    "eval_questions_nodes = data_generator_nodes.generate_questions_from_nodes()\n",
    "\n",
    "eval_questions_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 3 - дает больше одного"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Какие задачи решает ML-симулятор?',\n",
       " 'Какие данные хранятся в специальной базе данных в PostgreSQL?',\n",
       " 'Как Redash отображает результаты запросов?',\n",
       " 'Как Redash отображает время в своем формате?',\n",
       " 'Какие форматы отображения даты доступны в Redash?',\n",
       " 'Какие нюансы связаны с отображением времени в Redash?',\n",
       " 'Какие проблемы могут возникнуть при отборе записей по времени в Redash?',\n",
       " 'Как данные хранятся в базе данных PostgreSQL?',\n",
       " 'Какой формат времени используется в базе данных PostgreSQL?',\n",
       " 'Какие форматы времени поддерживает Redash?',\n",
       " 'Какие различия между форматом хранения данных и их отображением в Redash?']"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_gen_query = \"Я хочу создать список эталонных вопросов к корпусу текстов. \\\n",
    "                      Эталонный вопрос относится к области анализа данных\\\n",
    "                      и на него можно ответить с помощью соответствующего текста.\\\n",
    "                      Вопрос должен покрыть как можно больше аспектов в тексте.\\\n",
    "                      Составь один эталонный вопрос к этому тексту.\"\n",
    "\n",
    "\n",
    "data_generator_nodes = DatasetGenerator(\n",
    "    nodes=nodes[:2],\n",
    "    service_context=service_context_gpt3,\n",
    "    question_gen_query=question_gen_query\n",
    "    )\n",
    "\n",
    "eval_questions_nodes = data_generator_nodes.generate_questions_from_nodes()\n",
    "\n",
    "eval_questions_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 4 - сносно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Какие задачи можно решить с помощью ML-симулятора?',\n",
       " 'Какие данные хранятся в базе данных PostgreSQL?']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_gen_query = \"На русском языке. только один вопрос на текст! Это должен быть именно один вопрос\"\n",
    "\n",
    "data_generator_nodes = DatasetGenerator(\n",
    "    nodes=nodes[:2],\n",
    "    service_context=service_context_gpt3,\n",
    "    question_gen_query=question_gen_query\n",
    "    )\n",
    "\n",
    "eval_questions_nodes = data_generator_nodes.generate_questions_from_nodes()\n",
    "\n",
    "eval_questions_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 5 - твой вариант - больше двух вопросов на ноду"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Что такое Симулятор ML и для чего он нужен?',\n",
       " 'Какие задачи можно решить с помощью Симулятора ML?',\n",
       " 'Какой опыт можно получить, проходя Симулятор ML?',\n",
       " 'Как Симулятор ML поможет при приеме на работу?',\n",
       " 'Как Симулятор ML поможет при выполнении новых задач на работе?',\n",
       " 'Что такое Redash и как он отображает данные?',\n",
       " 'Где хранятся данные в Redash?',\n",
       " 'Как Redash отображает время?',\n",
       " 'Какой формат отображения даты использует Redash?',\n",
       " 'Какие нюансы есть в отображении данных в Redash?',\n",
       " 'Какие настройки есть в Redash для отображения даты?',\n",
       " 'Какие форматы даты можно использовать в Redash?',\n",
       " 'Какие данные хранятся в базе данных в формате PostgreSQL?',\n",
       " 'Какие проблемы могут возникнуть при отборе записей по времени в Redash?',\n",
       " 'Какие инструменты существуют для визуализации данных, похожие на Redash?']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator_nodes = DatasetGenerator(\n",
    "    nodes=nodes[:2],\n",
    "    service_context=service_context_gpt3,\n",
    "    num_questions_per_chunk=2,\n",
    "    question_gen_query=\"На русском языке\"\n",
    "    )\n",
    "\n",
    "eval_questions_nodes = data_generator_nodes.generate_questions_from_nodes()\n",
    "\n",
    "eval_questions_nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вариант 6 - пример того, как на некоторые ноды бот не приводит вопрос (см вторую ноду)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Какие задачи можно решить с помощью ML-симулятора?',\n",
       " 'Если бы мы просто перевели формат колонки Creation Time в текстовый формат, мы могли бы увидеть, как она выглядит. Однако, в Redash текстовый формат уже не форматирует данные, поэтому мы не можем узнать, как они хранятся в базе данных PostgreSQL.',\n",
       " 'Как можно интерпретировать график и сделать статистический вывод?',\n",
       " 'Какие задачи решает аналитик данных в банках?',\n",
       " 'Какие факторы могут влиять на то, что товарный запас не был распродан в некоторых магазинах?',\n",
       " 'Какие детали и нюансы вы заметили при рассмотрении задач других аналитиков?',\n",
       " 'Какие проблемы с организацией работы и атмосферой были упомянуты девочкой, которая работала в магните?',\n",
       " 'Какие проблемы возникли при выполнении проектов и как вы планируете к ним подходить в будущем?']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_generator_nodes_proc = DatasetGenerator(\n",
    "    nodes=processed_nodes,\n",
    "    service_context=service_context_gpt3,\n",
    "    # num_questions_per_chunk=1,\n",
    "    question_gen_query=question_gen_query\n",
    "    )\n",
    "\n",
    "eval_questions_nodes_proc = data_generator_nodes_proc.generate_questions_from_nodes()\n",
    "\n",
    "eval_questions_nodes_proc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "karpovai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
